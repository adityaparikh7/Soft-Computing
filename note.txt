def train(self, inputs, targets, learning_rate=0.1, epochs=100):
        for epoch in range(epochs):
            error = False
            for i in range(len(inputs)):
                prediction = self.predict(inputs[i])
                delta = targets[i] - prediction
                if delta != 0:
                    # Update weights and bias
                    self.weights += learning_rate * delta * inputs[i]
                    self.bias += learning_rate * delta
                    error = True

            # Display output for each epoch
            print(f"Epoch {epoch + 1}:")
            print(f"Weights: {self.weights}, Bias: {self.bias}")
            if not error:
                print("Converged")
                break

# Logic gates using bipolar inputs and targets
input_data = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])
and_targets = np.array([-1, -1, -1, 1])
or_targets = np.array([-1, 1, 1, 1])
nor_targets = np.array([1, -1, -1, -1])
nand_targets = np.array([1, 1, 1, -1])

# Create perceptrons for each logic gate
and_perceptron = Perceptron(input_size=2)
or_perceptron = Perceptron(input_size=2)
nor_perceptron = Perceptron(input_size=2)
nand_perceptron = Perceptron(input_size=2)

# Train perceptrons
print("Training AND gate:")
and_perceptron.train(input_data, and_targets)
print("\nTraining OR gate:")
or_perceptron.train(input_data, or_targets)
print("\nTraining NOR gate:")
nor_perceptron.train(input_data, nor_targets)
print("\nTraining NAND gate:")
nand_perceptron.train(input_data, nand_targets)